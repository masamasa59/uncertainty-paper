# Predictive Uncertainty
Prediction uncertainty is important for humans to trust machine learning systems.
This repository contains research papers on prediction uncertainty, quantification methods, applied topics, and user studies.

As a highway of knowledge, this repository has collected important papers to help you understand uncertainty with a minimum of effort.

I have collected papers from the following international conferences: ICML, NeurIPS, AAAI, IJCAI, ICLR, IUI, CHI


Keywords: 
`Data(Alealistic) Uncertainty`, `Model(Epistimic) Uncertainty`, `Bayesain Neural Networks`, `Deep Ensembles`, `Uncertainty visualization`, `Human-centered computing`, `Human-AI-Interaction`, `interpretability`, `XAI`


# Survey
* Gawlikowski, Jakob, et al. "A survey of uncertainty in deep neural networks." arXiv preprint arXiv:2107.03342 (2021).[[Link]](https://arxiv.org/abs/2107.03342)
* Zhou, Xinlei, et al. "A Survey on Epistemic (Model) Uncertainty in Supervised Learning: Recent Advances and Applications." Neurocomputing (2021).[[Link]](https://doi.org/10.1016/j.neucom.2021.10.119)
* E. Hu ̈llermeier and W. Waegeman, “Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods,” Machine Learning, vol. 110, no. 3, pp. 457–506, 2021. [[Link]](https://arxiv.org/abs/1910.09457)
 
* Abdar, Moloud, et al. "A review of uncertainty quantification in deep learning: Techniques, applications and challenges." Information Fusion (2021).[[Link]](https://doi.org/10.1016/j.inffus.2021.05.008)

* Meredith Skeels, Bongshin Lee, Greg Smith, and George Robertson. "Revealing uncertainty for information visualization." In Proceedings of the working conference on Advanced visual interfaces (AVI '08).[[Link]](https://dl.acm.org/doi/10.1145/1385569.1385637)

# Quantification Methods
### Single deterministic methods 
* Mukhoti, Jishnu, et al. "Deterministic Neural Networks with Inductive Biases Capture Epistemic and Aleatoric Uncertainty." arXiv preprint arXiv:2102.11582 (2021).[[Link]](https://arxiv.org/pdf/2102.11582)

* A. Malinin and M. Gales, “Predictive uncertainty estimation via prior networks,” in Advances in Neural Information Processing Systems, 2018, pp. 7047–7058.[[Link]](https://proceedings.neurips.cc/paper/2018/file/3ea2db50e62ceefceaf70a9d9a56a6f4-Paper.pdf)

* Ramalho, Tiago, and Miguel Miranda. "Density estimation in representation space to predict model uncertainty." International Workshop on Engineering Dependable and Secure Machine Learning Systems. Springer, Cham, 2020. [[Link]](https://arxiv.org/pdf/1908.07235)

* Sensoy, Murat, Lance Kaplan, and Melih Kandemir. "Evidential deep learning to quantify classification uncertainty." Advances in Neural Information Processing Systems 31 (2018).[[Link]](https://proceedings.neurips.cc/paper/2018/file/a981f2b708044d6fb4a71a1463242520-Paper.pdf)

### Ensembles
* Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. "Simple and scalable predictive uncertainty estimation using deep ensembles." Advances in neural information processing systems 30 (2017).[[Link]](https://proceedings.neurips.cc/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf)


* Valdenegro-Toro, Matias. "Deep sub-ensembles for fast uncertainty estimation in image classification." arXiv preprint arXiv:1910.08168 (2019). [[Link]](https://arxiv.org/pdf/1910.08168)

* Wen, Yeming, Dustin Tran, and Jimmy Ba. "Batchensemble: an alternative approach to efficient ensemble and lifelong learning." arXiv preprint arXiv:2002.06715 (2020).[[Link]](https://arxiv.org/pdf/2002.06715) 

### Bayesian methods
* Jospin, Laurent Valentin, et al. "Hands-on Bayesian neural networks--a tutorial for deep learning users." arXiv preprint arXiv:2007.06823 (2020). [[Link]](https://arxiv.org/abs/2007.06823)
* Uncertainty in Deep Learning (PhD Thesis)[[Link1]](https://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf)[[Link2]](https://www.cs.ox.ac.uk/people/yarin.gal/website/blog_2248.html)

* Izmailov, Pavel, et al. "What are Bayesian neural network posteriors really like?." International Conference on Machine Learning. PMLR, 2021. [[Link]](https://arxiv.org/abs/2104.14421)

### Test-time augmentation
* Ashukha, Arsenii, et al. "Pitfalls of in-domain uncertainty estimation and ensembling in deep learning." arXiv preprint arXiv:2002.06470 (2020).[[Link]](https://arxiv.org/pdf/2002.06470) 

* Shanmugam, Divya, et al. "When and why test-time augmentation works." arXiv e-prints (2020): arXiv-2011.[[Link]](https://arxiv.org/pdf/2011.11156.pdf)

### Embedding
* Postels, Janis, et al. "The hidden uncertainty in a neural networks activations." arXiv preprint arXiv:2012.03082 (2020).[[Link]](https://arxiv.org/pdf/2012.03082)

# Application
### Medical semantic segmentation
* Nair, Tanya, et al. "Exploring uncertainty measures in deep networks for multiple sclerosis lesion detection and segmentation." Medical image analysis 59 (2020): 101557. [[Link]](https://www.sciencedirect.com/science/article/pii/S1361841519300994?casa_token=xkmmdBQmXdgAAAAA:rDYDtqJ3WI7EXwAFXZWsVezsmi7vll8nYTVnw3pGNs2aEoUFIKuBjCVi5D7evvSaNdMxaLMDuQ)

### Automated driving semantic segmentation
* Kendall, Alex, Vijay Badrinarayanan, and Roberto Cipolla. "Bayesian segnet: Model uncertainty in deep convolutional encoder-decoder architectures for scene understanding." arXiv preprint arXiv:1511.02680 (2015).[[Link]](https://arxiv.org/pdf/1511.02680.pdf?source=post_page---------------------------)

### Active learning (Annotation)
* J. Zeng, A. Lesnikowski, and J. M. Alvarez, “The relevance of bayesian layer positioning to model uncertainty in deep bayesian active learning,” arXiv preprint arXiv:1811.12535, 2018. [[Link]](https://arxiv.org/pdf/1811.12535.pdf)

### Out of distribution detection 
* Postels, Janis, et al. "The hidden uncertainty in a neural networks activations." arXiv preprint arXiv:2012.03082 (2020).[[Link]](https://arxiv.org/pdf/2012.03082)

### Satellite image classification
* Gawlikowski, Jakob, et al. "Out-of-distribution detection in satellite image classification." arXiv preprint arXiv:2104.05442 (2021). [[Link]](https://arxiv.org/pdf/2104.05442)

### Dataset shift detection
* Ovadia, Yaniv, et al. "Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift." Advances in neural information processing systems 32 (2019). [[Link]](https://proceedings.neurips.cc/paper/2019/file/8558cb408c1d76621371888657d2eb1d-Paper.pdf)

### Natural language generation 
* Xiao, Yijun, and William Yang Wang. "On hallucination and predictive uncertainty in conditional language generation." arXiv preprint arXiv:2103.15025 (2021).[[Link]](https://arxiv.org/pdf/2103.15025)
 
### Safty reinforcement learning
* Sedlmeier, Andreas, et al. "Uncertainty-based out-of-distribution classification in deep reinforcement learning." arXiv preprint arXiv:2001.00496 (2019).[[Link]](https://arxiv.org/pdf/2001.00496)

### XAI
* Antorán, Javier, et al. "Getting a clue: A method for explaining uncertainty estimates." arXiv preprint arXiv:2006.06848 (2020). [[Link]](https://arxiv.org/abs/2006.06848)

### Transparency
* Bhatt, Umang, et al. "Uncertainty as a form of transparency: Measuring, communicating, and using uncertainty." Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society. 2021.[[Link]](https://dl.acm.org/doi/pdf/10.1145/3461702.3462571)

### Counterfactual explanations
* Schut, Lisa, et al. "Generating interpretable counterfactual explanations by implicit minimisation of epistemic and aleatoric uncertainties." International Conference on Artificial Intelligence and Statistics. PMLR, 2021.[[Link]](http://proceedings.mlr.press/v130/schut21a/schut21a.pdf)

### Robustness 
* Nado, Zachary, et al. "Uncertainty Baselines: Benchmarks for uncertainty & robustness in deep learning." arXiv preprint arXiv:2106.04015 (2021). [[Link]](https://arxiv.org/pdf/2106.04015)

### Calibration
* Guo, Chuan, et al. "On calibration of modern neural networks." International Conference on Machine Learning. PMLR, 2017.[[Link]](http://proceedings.mlr.press/v70/guo17a/guo17a.pdf)

* Minderer, Matthias, et al. "Revisiting the calibration of modern neural networks." Advances in Neural Information Processing Systems 34 (2021).[[Link]](https://proceedings.neurips.cc/paper/2021/file/8420d359404024567b5aefda1231af24-Paper.pdf)

### Example difficality
* Baldock, Robert, Hartmut Maennel, and Behnam Neyshabur. "Deep learning through the lens of example difficulty." Advances in Neural Information Processing Systems 34 (2021).[[Link]](https://arxiv.org/pdf/2106.09647.pdf)

* D'souza, Daniel, et al. "A Tale Of Two Long Tails." arXiv preprint arXiv:2107.13098 (2021).[[Link]](https://arxiv.org/pdf/2107.13098.pdf)
# User Study

### Uncertainty visualization
* Téo Sanchez, Baptiste Caramiaux, Pierre Thiel, Wendy E. Mackay. "Deep Learning Uncertainty in Machine Teaching." 27th Annual Conference on Intelligent User Interfaces, Mar 2022 [[Link]](https://hal.archives-ouvertes.fr/hal-03579448/document)

* McGrath, Sean, et al. "When does uncertainty matter?: Understanding the impact of predictive uncertainty in ML assisted decision making." arXiv preprint arXiv:2011.06167 (2020).[[Link]](https://arxiv.org/pdf/2011.06167)

* Tak, Susanne, Alexander Toet, and Jan van Erp. "The perception of visual uncertaintyrepresentation by non-experts." IEEE transactions on visualization and computer graphics 20.6 (2013): 935-943.[[Link]](https://ieeexplore.ieee.org/iel7/2945/6805245/06654171.pdf?casa_token=WVSULJ9m1-AAAAAA:xNSXStIa4nVhlv19ixLkiFJ9Dk_wvJReKFv2nTLVM92tozGs_4QUvBLlUjIWta3aAsFY22i5pg)

### Application
* Miriam Greis, Emre Avci, Albrecht Schmidt, and Tonja Machulla. "Increasing Users' Confidence in Uncertain Data by Aggregating Data from Multiple Sources." In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). [[Link]](https://doi.org/10.1145/3025453.3025998)

* Yunfeng Zhang, Q. Vera Liao, and Rachel K. E. Bellamy."Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making." In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20).[[Link]](https://arxiv.org/pdf/2001.02114.pdf)

* Matthew Kay, Tara Kola, Jessica R. Hullman, and Sean A. Munson. "When (ish) is My Bus? User-centered Visualizations of Uncertainty in Everyday, Mobile Predictive Systems." In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16).[[Link]](https://idl.cs.washington.edu/files/2016-WhenIsMyBus-CHI.pdf)